<!DOCTYPE html>
<html>
<head>
<link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
<link rel="stylesheet" href="https://code.getmdl.io/1.2.1/material.deep_orange-blue.min.css">
<script src="https://code.getmdl.io/1.2.1/material.min.js" defer></script><meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
.demo-ribbon {
  width: 100%;
  height: 40vh;
  //background-image: url("hero.png");
  background-color: #f5f5f5;
  flex-shrink: 0;
}

.demo-main {
  margin-top: -35vh;
  flex-shrink: 0;
}

.demo-header .mdl-layout__header-row {
  padding-left: 40px;
}

.demo-container {
  max-width: 1600px;
  width: calc(100% - 16px);
  margin: 0 auto;
}

.demo-content {
  border-radius: 2px;
  padding: 80px 56px;
  margin-bottom: 80px;
}

.demo-layout.is-small-screen .demo-content {
  padding: 40px 28px;
}

.demo-content h3 {
  margin-top: 48px;
}

.demo-footer {
  padding-left: 40px;
}

.demo-footer .mdl-mini-footer--link-list a {
  font-size: 13px;
}
#view-source {
    float: right;
}
</style>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$']],
      processEscapes: true,
    }
  }
  </script><script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script><script type="text/javascript" src="../mermaid.min.js" async></script><link rel="stylesheet" href="../colorful.css">
<link rel="stylesheet" href="../styles.css">
<link rel="stylesheet" href="../pygments.css">
<link rel="stylesheet" href="../colorful.css">
<script>
                    function show(toExpand)
                    {
                    if(
                       document.getElementById(toExpand).style.display == 'none'
                       ||
                       document.getElementById(toExpand).style.display == ''
                       )
                        document.getElementById(toExpand).style.display = 'block';
                    else
                        document.getElementById(toExpand).style.display = 'none';
                    }
                    </script><style></style>
</head>
<body><div class="demo-layout mdl-layout mdl-layout--fixed-header mdl-js-layout mdl-color--grey-100">
<header class="demo-header mdl-layout__header mdl-layout__header--scroll mdl-color--grey-100 mdl-color-text--grey-800"><div class="mdl-layout__header-row">
<span class="mdl-layout-title"><a href="../index.html" style="text-decoration:none; color:#444;" class="mdl-typography--headline">Tom Bertalan</a></span><div class="mdl-layout-spacer"></div>
</div></header><div class="demo-ribbon"></div>
<main class="demo-main mdl-layout__content"><div class="demo-container mdl-grid">
<div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
<div class="demo-content mdl-color--white mdl-shadow--4dp content mdl-color-text--grey-800 mdl-cell mdl-cell--8-col">
<div class="demo-crumbs mdl-color-text--grey-500">
<a href="../index.html">Home</a> &gt; <span>Local Neural Text-to-Speech App</span><a href="http://github.com/tsbertalan/TextToSpeechLocal" id="view-source" class="mdl-button mdl-js-button mdl-button--raised mdl-js-ripple-effect mdl-color--accent mdl-color-text--accent-contrast">Project Files</a>
</div>
<span></span><h1>Local Neural Text-to-Speech App</h1>

<p><img alt="hero" src="local_tts.png"></p>

<p>On Android, <a href="http://getpocket.com">Pocket</a> provides a nice text-to-speech feature that lets you listen to articles you've saved that you don't care enough about to actually read with your human eyes and full attention. But they don't do this in their browser-based desktop site.</p>

<p>So, here's a crappy little app that does that. It's a local-only text-to-speech app in PyTorch using TacoTron2 for spectrogram generation and WaveGlow for audio synthesis.</p>

<p>Two worker threads handle the work: one to make the waves, and the other to speak them. The GUI breaks the given text up into chunks at sentence-like boundaries (using a few whitelisting regexes followed by a few blacklisting regexes to find those boundaries) and pushes them onto a first queue.</p>

<p>The first worker thread preprocesses this text to tokens, ~tacotron2s it to a spectrogram, waveglows it to a big 1D array~ uses the turnkey Silero offline PyTorch TTS engine to make a wave from this, and pushes that to a queue for our UI to ingest.</p>

<p>The second worker thread pops dictionaries containing audio and metadata off a different queue, and plays the audio out loud (blocking that thread appropriately).</p>

<p>There's a nice little GUI that lets you type in text and add it to the queue,
with some information that's probably ultimately useless to the user; namely the length of the two queues, and messages returned from the two workers in a autoscrolling log box.</p>

<p>Underneath the log window, there's a scrollable canvas of buttons to play the indicated results. If you click one, it and all following boxes change text color to blue to indicate they're queued for playing. Then the player worker starts popping them, and turning them green as it goes.</p>

<p>Some problems I could eventually fix:</p>

<ul class="task-list">
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled checked><span class="task-list-indicator"></span></label> The actual voice is pretty rough. Get a better model. WaveRNN is much nicer, but too slow without smarter chunking. <em>After the author provided a workaround for a <a href="https://github.com/snakers4/silero-models/discussions/245">bug I reported</a>, I can now use all 117 of the Silero voices, which are good enough for me. Tacotron+WaveRNN would still be preferable if I could get it fast enough, though.</em>
</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled checked><span class="task-list-indicator"></span></label> Sometimes the player thread runs out of of things to say because the model thread is too slow to generate them. Not sure what can be done about this. <em>Silero seems fast enough for this not to be a problem.</em>
</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled checked><span class="task-list-indicator"></span></label> Get the memory usage down. It's something like 5.3GB! Maybe quantized models could help with this.</li>
<li>Well, actually, Process Explorer reports a much smaller number? Hard to tell.</li>
<li>It now (with the Silero model) seems that it's more like 200MB of CPU memory (I'm still unsure about it's actual GPU memory, which was what the 5.3GB number was about) when doing nothing,<ul>
<li>plus maybe 10MB per sentence when they're sitting in the the TTS queue</li>
<li>plus about 1MB per sentence when they're sitting in the speaker queue</li>
</ul>
</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Worse, sometimes the sentence is too long for the TacoTron, and it starts outputing gibberish. Do smaller chunks.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Improve the playhead UI.<ul class="task-list">
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled checked><span class="task-list-indicator"></span></label> Don't just discard converted audio--let the user go back to previous chunks with the playhead.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Add pause buttons, not just stop-all.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Indicate how much of the text is converted to audio with some kind of "buffering" playhead indicator.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Maybe instead of buttons for TTS'd sentences, have a text canvas with clickable regions. Much easier to scan visually.</li>
</ul>
</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Use a prettier UI style.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Make the UI at least somewhat rescalable.</li>
<li class="task-list-item">
<label class="task-list-control"><input type="checkbox" disabled><span class="task-list-indicator"></span></label> Add a checkbox to enable pausing autoscrolling of the log (or just drop the log if the UI is informative enough).</li>
</ul>

<h2>Installation and Usage</h2>

<p>Use some recent Python 3 (I think 3.6+ is required).</p>

<p>Install the requirements:</p>

<div class="codehilite"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements_pytorch_gpu_cu118.txt
</pre></div>

<p>Or, you could skip the second line and use PyTorch's instructions to get the corresonding pacakges for your platform.</p>

<p>I don't know whether all those packages would be avalable on Anaconda; use conda-forge or something, I guess.</p>

<p>Then, run the app:</p>

<div class="codehilite"><pre><span></span>python<span class="w"> </span>app.py
</pre></div>

<p>Ctrl+C or close the window to quit. </p>
</div>
<div class="mdl-cell mdl-cell--2-col mdl-cell--hide-tablet mdl-cell--hide-phone"></div>
</div></main>
</div></body>
</html>
